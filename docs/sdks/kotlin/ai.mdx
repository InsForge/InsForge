---
title: AI SDK Reference
description: AI chat completions and image generation with the InsForge Kotlin SDK
---

import KotlinSdkInstallation from '/snippets/kotlin-sdk-installation.mdx';

## Installation

<KotlinSdkInstallation />

---

## listModels()

List all available AI models.

### Example

```kotlin
val models = client.ai.listModels()

models.forEach { model ->
    println("${model.provider}/${model.modelId}")
    println("  Input: ${model.inputModality}, Output: ${model.outputModality}")
    println("  Max tokens: ${model.maxTokens}")
}
```

---

## chatCompletion()

Create an AI chat completion.

### Parameters

- `model` (String) - Model identifier (e.g., "anthropic/claude-3.5-haiku")
- `messages` (`List<ChatMessage>`) - Conversation messages
- `temperature` (Double?, optional) - Sampling temperature (0.0-2.0)
- `maxTokens` (Int?, optional) - Maximum tokens to generate
- `systemPrompt` (String?, optional) - System prompt

### Returns

```kotlin
ChatCompletionResponse
```

### Example (Basic)

```kotlin
val response = client.ai.chatCompletion(
    model = "anthropic/claude-3.5-haiku",
    messages = listOf(
        ChatMessage(role = "user", content = "What is the capital of France?")
    )
)

println(response.content)  // Direct access to content
println("Tokens used: ${response.metadata.usage.totalTokens}")
```

### Example (With Parameters)

```kotlin
val response = client.ai.chatCompletion(
    model = "openai/gpt-4",
    messages = listOf(
        ChatMessage(role = "system", content = "You are a helpful assistant."),
        ChatMessage(role = "user", content = "Explain quantum computing in simple terms")
    ),
    temperature = 0.7,
    maxTokens = 1000
)

println(response.content)
```

### Example (Multi-turn Conversation)

```kotlin
val conversationHistory = mutableListOf<ChatMessage>()

// First message
conversationHistory.add(ChatMessage(role = "user", content = "What is Kotlin?"))

val response1 = client.ai.chatCompletion(
    model = "anthropic/claude-3.5-haiku",
    messages = conversationHistory
)

conversationHistory.add(ChatMessage(role = "assistant", content = response1.content))

// Follow-up
conversationHistory.add(ChatMessage(role = "user", content = "What are its main features?"))

val response2 = client.ai.chatCompletion(
    model = "anthropic/claude-3.5-haiku",
    messages = conversationHistory
)

println(response2.content)
```

---

## chatCompletionStream()

Create a streaming chat completion. Returns `Flow<String>` that emits content chunks directly.

### Example

```kotlin
client.ai.chatCompletionStream(
    model = "anthropic/claude-3.5-haiku",
    messages = listOf(
        ChatMessage(role = "user", content = "Tell me a story")
    )
).collect { content ->
    print(content)  // Content string directly
}
```

### Example (With StringBuilder)

```kotlin
val fullResponse = StringBuilder()

client.ai.chatCompletionStream(
    model = "openai/gpt-4",
    messages = listOf(
        ChatMessage(role = "user", content = "Explain quantum computing")
    ),
    temperature = 0.7
).collect { content ->
    fullResponse.append(content)
    // Update UI with each chunk
    updateUI(fullResponse.toString())
}

println("Complete response: $fullResponse")
```

---

## generateImage()

Generate images using AI models.

### Parameters

- `model` (String) - Image generation model (e.g., "openai/dall-e-3")
- `prompt` (String) - Image description

### Returns

```kotlin
ImageGenerationResponse
```

### Example

```kotlin
val response = client.ai.generateImage(
    model = "google/gemini-2.5-flash-image-preview",
    prompt = "A serene mountain landscape at sunset"
)

println("Generated ${response.count} image(s)")

response.images.forEach { image ->
    val imageUrl = image.imageUrl.url

    if (imageUrl.startsWith("data:image")) {
        // Handle base64 encoded image
        val base64Data = imageUrl.substringAfter("base64,")
        val imageData = Base64.decode(base64Data, Base64.DEFAULT)
        val bitmap = BitmapFactory.decodeByteArray(imageData, 0, imageData.size)
        imageView.setImageBitmap(bitmap)
    } else {
        // Handle URL - load with Coil/Glide
        // AsyncImage(model = imageUrl, ...)
    }
}
```

### Example (Save to Storage)

```kotlin
val response = client.ai.generateImage(
    model = "openai/dall-e-3",
    prompt = "A futuristic city skyline"
)

response.images.firstOrNull()?.let { image ->
    val imageUrl = image.imageUrl.url

    if (imageUrl.startsWith("data:image")) {
        val base64Data = imageUrl.substringAfter("base64,")
        val imageData = Base64.decode(base64Data, Base64.DEFAULT)

        // Upload to storage
        val uploadResult = client.storage
            .from("ai-images")
            .uploadWithAutoKey("generated.png", imageData) {
                contentType = "image/png"
            }

        // Save reference to database
        client.database
            .from("generated_images")
            .insertTyped(listOf(
                GeneratedImageRecord(
                    prompt = "A futuristic city skyline",
                    imageUrl = uploadResult.url
                )
            ))
            .returning()
            .execute<GeneratedImageRecord>()

        Log.d("AI", "Image saved: ${uploadResult.url}")
    }
}
```

---

## Jetpack Compose Integration

### Chat Screen

```kotlin
@Composable
fun ChatScreen() {
    var messages by remember { mutableStateOf<List<ChatMessage>>(emptyList()) }
    var inputText by remember { mutableStateOf("") }
    var isLoading by remember { mutableStateOf(false) }
    val scope = rememberCoroutineScope()

    Column(modifier = Modifier.fillMaxSize()) {
        LazyColumn(
            modifier = Modifier
                .weight(1f)
                .padding(16.dp),
            reverseLayout = true
        ) {
            items(messages.reversed()) { message ->
                ChatBubble(message = message)
            }
        }

        Row(
            modifier = Modifier
                .fillMaxWidth()
                .padding(16.dp)
        ) {
            OutlinedTextField(
                value = inputText,
                onValueChange = { inputText = it },
                modifier = Modifier.weight(1f),
                placeholder = { Text("Message") }
            )

            Spacer(modifier = Modifier.width(8.dp))

            IconButton(
                onClick = {
                    if (inputText.isNotBlank() && !isLoading) {
                        val userMessage = ChatMessage(role = "user", content = inputText)
                        messages = messages + userMessage
                        val currentInput = inputText
                        inputText = ""

                        scope.launch {
                            isLoading = true
                            try {
                                val response = client.ai.chatCompletion(
                                    model = "anthropic/claude-3.5-haiku",
                                    messages = messages
                                )
                                messages = messages + ChatMessage(
                                    role = "assistant",
                                    content = response.content
                                )
                            } catch (e: Exception) {
                                Log.e("Chat", "Error: ${e.message}")
                            } finally {
                                isLoading = false
                            }
                        }
                    }
                },
                enabled = inputText.isNotBlank() && !isLoading
            ) {
                Icon(Icons.Default.Send, "Send")
            }
        }
    }
}

@Composable
fun ChatBubble(message: ChatMessage) {
    val isUser = message.role == "user"

    Row(
        modifier = Modifier
            .fillMaxWidth()
            .padding(vertical = 4.dp),
        horizontalArrangement = if (isUser) Arrangement.End else Arrangement.Start
    ) {
        Card(
            colors = CardDefaults.cardColors(
                containerColor = if (isUser)
                    MaterialTheme.colorScheme.primary
                else
                    MaterialTheme.colorScheme.surfaceVariant
            )
        ) {
            Text(
                text = message.content,
                modifier = Modifier.padding(12.dp),
                color = if (isUser)
                    MaterialTheme.colorScheme.onPrimary
                else
                    MaterialTheme.colorScheme.onSurfaceVariant
            )
        }
    }
}
```

### Streaming Chat

```kotlin
@Composable
fun StreamingChatScreen() {
    var response by remember { mutableStateOf("") }
    var isStreaming by remember { mutableStateOf(false) }
    var prompt by remember { mutableStateOf("") }
    val scope = rememberCoroutineScope()

    Column(
        modifier = Modifier
            .fillMaxSize()
            .padding(16.dp)
    ) {
        OutlinedTextField(
            value = prompt,
            onValueChange = { prompt = it },
            label = { Text("Your question") },
            modifier = Modifier.fillMaxWidth()
        )

        Spacer(modifier = Modifier.height(16.dp))

        Button(
            onClick = {
                scope.launch {
                    isStreaming = true
                    response = ""

                    try {
                        client.ai.chatCompletionStream(
                            model = "anthropic/claude-3.5-haiku",
                            messages = listOf(
                                ChatMessage(role = "user", content = prompt)
                            )
                        ).collect { content ->
                            response += content
                        }
                    } catch (e: Exception) {
                        Log.e("Stream", "Error: ${e.message}")
                    } finally {
                        isStreaming = false
                    }
                }
            },
            enabled = prompt.isNotBlank() && !isStreaming,
            modifier = Modifier.fillMaxWidth()
        ) {
            Text(if (isStreaming) "Streaming..." else "Ask AI")
        }

        Spacer(modifier = Modifier.height(16.dp))

        Text(
            text = response,
            modifier = Modifier
                .weight(1f)
                .verticalScroll(rememberScrollState())
        )
    }
}
```

### Image Generation Screen

```kotlin
@Composable
fun ImageGenerationScreen() {
    var prompt by remember { mutableStateOf("") }
    var generatedBitmap by remember { mutableStateOf<Bitmap?>(null) }
    var isGenerating by remember { mutableStateOf(false) }
    val scope = rememberCoroutineScope()

    Column(
        modifier = Modifier
            .fillMaxSize()
            .padding(16.dp),
        horizontalAlignment = Alignment.CenterHorizontally
    ) {
        OutlinedTextField(
            value = prompt,
            onValueChange = { prompt = it },
            label = { Text("Describe your image...") },
            modifier = Modifier.fillMaxWidth()
        )

        Spacer(modifier = Modifier.height(16.dp))

        Button(
            onClick = {
                scope.launch {
                    isGenerating = true
                    try {
                        val response = client.ai.generateImage(
                            model = "google/gemini-2.5-flash-image-preview",
                            prompt = prompt
                        )

                        response.images.firstOrNull()?.let { image ->
                            val imageUrl = image.imageUrl.url

                            if (imageUrl.startsWith("data:image")) {
                                val base64Data = imageUrl.substringAfter("base64,")
                                val data = Base64.decode(base64Data, Base64.DEFAULT)
                                generatedBitmap = BitmapFactory.decodeByteArray(
                                    data, 0, data.size
                                )
                            }
                        }
                    } catch (e: Exception) {
                        Log.e("ImageGen", "Failed: ${e.message}")
                    } finally {
                        isGenerating = false
                    }
                }
            },
            enabled = prompt.isNotBlank() && !isGenerating,
            modifier = Modifier.fillMaxWidth()
        ) {
            Text(if (isGenerating) "Generating..." else "Generate Image")
        }

        Spacer(modifier = Modifier.height(16.dp))

        if (isGenerating) {
            CircularProgressIndicator()
        }

        generatedBitmap?.let { bitmap ->
            Image(
                bitmap = bitmap.asImageBitmap(),
                contentDescription = "Generated image",
                modifier = Modifier
                    .fillMaxWidth()
                    .height(300.dp)
            )
        }
    }
}
```

---

## Error Handling

```kotlin
import dev.insforge.exceptions.InsforgeHttpException
import dev.insforge.exceptions.InsforgeException

try {
    val response = client.ai.chatCompletion(
        model = "anthropic/claude-3.5-haiku",
        messages = listOf(ChatMessage(role = "user", content = "Hello"))
    )
    println(response.content)
} catch (e: InsforgeHttpException) {
    when (e.error) {
        "MODEL_NOT_FOUND" -> println("Model not available")
        "RATE_LIMIT_EXCEEDED" -> println("Rate limit exceeded, try again later")
        "INVALID_REQUEST" -> println("Invalid request: ${e.message}")
        else -> println("API Error: ${e.message}")
    }
} catch (e: InsforgeException) {
    println("SDK Error: ${e.message}")
}
```

---

## Models Reference

### ChatMessage

```kotlin
@Serializable
data class ChatMessage(
    val role: String,  // "user", "assistant", "system"
    val content: String
)
```

### ChatCompletionResponse

```kotlin
@Serializable
data class ChatCompletionResponse(
    val success: Boolean,
    val content: String,
    val metadata: CompletionMetadata
)

@Serializable
data class CompletionMetadata(
    val model: String,
    val usage: TokenUsage
)

@Serializable
data class TokenUsage(
    @SerialName("prompt_tokens") val promptTokens: Int,
    @SerialName("completion_tokens") val completionTokens: Int,
    @SerialName("total_tokens") val totalTokens: Int
)
```

### ImageGenerationResponse

```kotlin
@Serializable
data class ImageGenerationResponse(
    val model: String,
    val images: List<GeneratedImage>,
    val text: String? = null,
    val count: Int,
    val metadata: ImageMetadata,
    val nextActions: String
)

@Serializable
data class GeneratedImage(
    val type: String,  // "image_url"
    @SerialName("image_url") val imageUrl: ImageUrl
)

@Serializable
data class ImageUrl(
    val url: String  // URL or data:image/... base64
)

@Serializable
data class ImageMetadata(
    val model: String,
    val provider: String
)
```

### AIModel

```kotlin
@Serializable
data class AIModel(
    val id: String,
    val provider: String,
    val modelId: String,
    val inputModality: String,  // "text", "image", etc.
    val outputModality: String,
    val maxTokens: Int? = null
)
```
