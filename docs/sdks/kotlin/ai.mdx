---
title: AI SDK Reference
description: AI chat completions, web search, file parsing, and image generation with the InsForge Kotlin SDK
---

import KotlinSdkInstallation from '/snippets/kotlin-sdk-installation.mdx';

## Installation

<KotlinSdkInstallation />

---

## listModels()

List all available AI models.

### Example

```kotlin
val models = client.ai.listModels()

models.forEach { model ->
    println("${model.provider}/${model.modelId}")
    println("  Input: ${model.inputModality}, Output: ${model.outputModality}")
    println("  Max tokens: ${model.maxTokens}")
}
```

---

## chatCompletion()

Create an AI chat completion.

### Parameters

- `model` (String) - Model identifier (e.g., "anthropic/claude-3.5-haiku", "openai/gpt-4o")
- `messages` (`List<ChatMessage>`) - Conversation messages
- `temperature` (Double?, optional) - Sampling temperature (0.0-2.0)
- `maxTokens` (Int?, optional) - Maximum tokens to generate
- `systemPrompt` (String?, optional) - System prompt
- `webSearch` (WebSearchPlugin?, optional) - Enable web search capabilities
- `fileParser` (FileParserPlugin?, optional) - Enable file/PDF parsing

### Returns

```kotlin
ChatCompletionResponse
```

### Example (Basic)

```kotlin
val response = client.ai.chatCompletion(
    model = "anthropic/claude-3.5-haiku",
    messages = listOf(
        ChatMessage.user("What is the capital of France?")
    )
)

println(response.text)  // Direct access to text content
println("Tokens used: ${response.metadata.usage.totalTokens}")

// Access annotations if available
response.annotations?.forEach { annotation ->
    println("Citation: ${annotation.urlCitation.url}")
}
```

### Multimodal Messages

The SDK supports multimodal messages with images, PDFs, and audio.

```kotlin
// Simple text message (backward compatible)
val response = client.ai.chatCompletion(
    model = "openai/gpt-4",
    messages = listOf(ChatMessage.user("Hello!"))
)

// Custom multimodal message with multiple content parts
val customMessage = ChatMessage.multimodal(
    "user",
    TextContent(text = "Describe these images"),
    ImageContent(imageUrl = ImageUrlConfig(url = "https://example.com/1.jpg")),
    ImageContent(imageUrl = ImageUrlConfig(url = "https://example.com/2.jpg"))
)

val response = client.ai.chatCompletion(
    model = "anthropic/claude-sonnet-4.5",
    messages = listOf(customMessage)
)
```

### Example (With Web Search)

```kotlin
val response = client.ai.chatCompletion(
    model = "openai/gpt-4",
    messages = listOf(
        ChatMessage.user("What are the latest news about AI?")
    ),
    webSearch = WebSearchPlugin(
        enabled = true,
        maxResults = 5,
        engine = WebSearchEngine.NATIVE
    )
)

println(response.text)

// Access URL citations from search results
response.annotations?.forEach { annotation ->
    println("Source: ${annotation.urlCitation.title} - ${annotation.urlCitation.url}")
}
```

### Example (With PDF Parsing)

```kotlin
// Using the convenience method
val response = client.ai.chatCompletionWithFile(
    model = "anthropic/claude-sonnet-4.5",
    text = "Summarize the content of this PDF",
    filename = "document.pdf",
    fileData = "https://example.com/document.pdf",
    pdfEngine = PdfEngine.MISTRAL_OCR
)

println(response.text)

// Or using custom multimodal message
val pdfMessage = ChatMessage.multimodal(
    "user",
    TextContent(text = "Summarize this document"),
    FileContent(
        file = FileConfig(
            filename = "document.pdf",
            fileData = "https://example.com/document.pdf"
        )
    )
)

val response2 = client.ai.chatCompletion(
    model = "anthropic/claude-sonnet-4.5",
    messages = listOf(pdfMessage),
    fileParser = FileParserPlugin(
        enabled = true,
        pdf = PdfParserConfig(engine = PdfEngine.MISTRAL_OCR)
    )
)

println(response2.text)
```

---

## chatCompletionWithImages()

Convenience method for chat completion with image analysis.

### Parameters

- `model` (String) - Model identifier (must support vision, e.g., "openai/gpt-4o")
- `text` (String) - Text prompt to accompany the images
- `imageUrls` (List\<String\>) - List of image URLs to analyze
- `temperature` (Double?, optional) - Sampling temperature
- `maxTokens` (Int?, optional) - Maximum tokens to generate

### Example

```kotlin
val response = client.ai.chatCompletionWithImages(
    model = "openai/gpt-4o",
    text = "What is in this image?",
    imageUrls = listOf("https://example.com/image.jpg")
)

println(response.text)
```

---

## chatCompletionWithFile()

Convenience method for chat completion with file (PDF) analysis.

### Parameters

- `model` (String) - Model identifier
- `text` (String) - Text prompt to accompany the file
- `filename` (String) - Name of the file (e.g., "report.pdf")
- `fileData` (String) - File URL or base64-encoded data URL
- `pdfEngine` (PdfEngine?, optional) - PDF processing engine
- `temperature` (Double?, optional) - Sampling temperature
- `maxTokens` (Int?, optional) - Maximum tokens to generate

### Example (Base64 Encoded)

```kotlin
// Load PDF from local file
val pdfBytes = File("document.pdf").readBytes()
val base64Data = "data:application/pdf;base64,${Base64.encodeToString(pdfBytes, Base64.NO_WRAP)}"

val response = client.ai.chatCompletionWithFile(
    model = "anthropic/claude-sonnet-4.5",
    text = "What are the key points in this document?",
    filename = "document.pdf",
    fileData = base64Data
)

println(response.text)
```

---

## chatCompletionWithWebSearch()

Convenience method for chat completion with web search enabled.

### Parameters

- `model` (String) - Model identifier
- `messages` (`List<ChatMessage>`) - Conversation messages
- `maxResults` (Int?, optional) - Maximum search results (default: 5)
- `engine` (WebSearchEngine?, optional) - Search engine to use
- `temperature` (Double?, optional) - Sampling temperature
- `maxTokens` (Int?, optional) - Maximum tokens to generate

### Example

```kotlin
val response = client.ai.chatCompletionWithWebSearch(
    model = "openai/gpt-4o",
    messages = listOf(
        ChatMessage(role = "user", content = MessageContent.Text("What are today's top news headlines?"))
    ),
    maxResults = 5
)

println(response.text)

// Access citations
response.annotations?.forEach { annotation ->
    println("- ${annotation.urlCitation.title}: ${annotation.urlCitation.url}")
}
```

---

## chatCompletionStream()

Create a streaming chat completion. Returns `Flow<String>` that emits content chunks directly.

### Parameters

- `model` (String) - Model identifier
- `messages` (`List<ChatMessage>`) - Conversation messages
- `temperature` (Double?, optional) - Sampling temperature
- `maxTokens` (Int?, optional) - Maximum tokens to generate
- `webSearch` (WebSearchPlugin?, optional) - Enable web search capabilities
- `fileParser` (FileParserPlugin?, optional) - Enable file/PDF parsing
- `thinking` (Boolean?, optional) - Enable extended reasoning mode

### Example

```kotlin
client.ai.chatCompletionStream(
    model = "anthropic/claude-3.5-haiku",
    messages = listOf(
        ChatMessage(role = "user", content = "Tell me a story")
    )
).collect { content ->
    print(content)  // Content string directly
}
```

---

## generateEmbeddings()

Generate vector embeddings for text input using AI models.

### Parameters

- `model` (String) - Embedding model identifier (e.g., "google/gemini-embedding-001")
- `input` (String?, optional) - Single text input to embed
- `inputs` (List\<String\>?, optional) - Multiple text inputs to embed
- `encodingFormat` (EmbeddingEncodingFormat?, optional) - Output format (FLOAT or BASE64)
- `dimensions` (Int?, optional) - Number of dimensions for the output embeddings

### Returns

```kotlin
EmbeddingsResponse
```

### Example (With Optional Parameters)

```kotlin
val response = client.ai.generateEmbeddings(
    model = "google/gemini-embedding-001",
    input = "Hello world",
    encodingFormat = EmbeddingEncodingFormat.FLOAT,
    dimensions = 512
)

println("Embedding dimensions: ${response.data.first().embedding.size}")  // 512
```

---

## generateImage()

Generate images using AI models.

### Parameters

- `model` (String) - Image generation model (e.g., "openai/dall-e-3")
- `prompt` (String) - Image description

### Returns

```kotlin
ImageGenerationResponse
```

### Example

```kotlin
val response = client.ai.generateImage(
    model = "google/gemini-2.5-flash-image-preview",
    prompt = "A serene mountain landscape at sunset"
)

println("Generated ${response.count} image(s)")

response.images.forEach { image ->
    val imageUrl = image.imageUrl.url

    if (imageUrl.startsWith("data:image")) {
        // Handle base64 encoded image
        val base64Data = imageUrl.substringAfter("base64,")
        val imageData = Base64.decode(base64Data, Base64.DEFAULT)
        val bitmap = BitmapFactory.decodeByteArray(imageData, 0, imageData.size)
        imageView.setImageBitmap(bitmap)
    } else {
        // Handle URL - load with Coil/Glide
        // AsyncImage(model = imageUrl, ...)
    }
}
```

---

## Error Handling

```kotlin
import dev.insforge.exceptions.InsforgeHttpException
import dev.insforge.exceptions.InsforgeException

try {
    val response = client.ai.chatCompletion(
        model = "anthropic/claude-3.5-haiku",
        messages = listOf(ChatMessage(role = "user", content = "Hello"))
    )
    println(response.text)
} catch (e: InsforgeHttpException) {
    when (e.error) {
        "MODEL_NOT_FOUND" -> println("Model not available")
        "RATE_LIMIT_EXCEEDED" -> println("Rate limit exceeded, try again later")
        "INVALID_REQUEST" -> println("Invalid request: ${e.message}")
        else -> println("API Error: ${e.message}")
    }
} catch (e: InsforgeException) {
    println("SDK Error: ${e.message}")
}
```
